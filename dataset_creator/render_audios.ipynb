{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 'CLIENT_ID'\n",
    "client_secret = 'CLIENT_SECRET'\n",
    "auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_leading_silence\n",
    "\n",
    "trim_leading_silence = lambda x: x[detect_leading_silence(x) :]\n",
    "trim_trailing_silence = lambda x: trim_leading_silence(x.reverse()).reverse()\n",
    "strip_silence = lambda x: trim_trailing_silence(trim_leading_silence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "genres = os.listdir(\"./MIDIs\")\n",
    "instruments = os.listdir(\"./instruments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_dict = {\n",
    "    0: 'C', 1: 'C#',\n",
    "    2: 'D', 3: 'D#',\n",
    "    4: 'E',\n",
    "    5: 'F', 6: 'F#',\n",
    "    7: 'G', 8: 'G#',\n",
    "    9: 'A', 10: 'A#',\n",
    "    11: 'B'\n",
    "}\n",
    "\n",
    "mode_dict = {\n",
    "    0: 'Minor', 1: 'Major'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from midi2audio import FluidSynth\n",
    "from pedalboard import Pedalboard, Compressor, Phaser, Chorus, Bitcrush, Delay, Reverb\n",
    "from pedalboard.io import AudioFile\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('tmp', exist_ok=True)\n",
    "os.makedirs('renders', exist_ok=True)\n",
    "id = 0\n",
    "for _ in range(1):\n",
    "    # Pick song\n",
    "    general_genre = random.choice(genres)\n",
    "    specific_genre = random.choice(os.listdir(f\"./MIDIs/{general_genre}\"))\n",
    "    artist = random.choice(os.listdir(f\"./MIDIs/{general_genre}/{specific_genre}\"))\n",
    "    song = random.choice(os.listdir(f\"./MIDIs/{general_genre}/{specific_genre}/{artist}\"))\n",
    "\n",
    "    # Render MIDI\n",
    "    instrument = random.choice(instruments)\n",
    "    fs = FluidSynth(f'./instruments/{instrument}', sample_rate=44100)\n",
    "    fs.midi_to_audio(f'./MIDIs/{general_genre}/{specific_genre}/{artist}/{song}',\n",
    "                     './tmp/render.wav')\n",
    "\n",
    "    # Find it on Spotify\n",
    "    spotify_track = sp.search(artist + \" \" + song[:-4], limit=1, type='track')\n",
    "    if len(spotify_track['tracks']['items']) == 0: continue\n",
    "    track_id = spotify_track['tracks']['items'][0]['id']\n",
    "\n",
    "    # Get Spotify's Audio Features\n",
    "    spotify_features = sp.audio_features([track_id])\n",
    "    # acousticness = spotify_features[0]['acousticness'] # (maybe) Doesn't make sense, depends heavily on all instruments\n",
    "    danceability = spotify_features[0]['danceability'] # Might depend on a lot of other instruments\n",
    "    energy = spotify_features[0]['energy'] # Might depend on a lot of other instruments, mostly drums, but ok\n",
    "    # instrumentalness = spotify_features[0]['instrumentalness'] # Doesn't make sense, it'll be just piano\n",
    "\n",
    "    # Get Spotify's Audio Analysis\n",
    "    spotify_analysis = sp.audio_analysis(track_id)\n",
    "    audio = AudioSegment.from_wav('./tmp/render.wav')\n",
    "    for section in spotify_analysis[\"sections\"]:\n",
    "        # Cut section of rendered audio\n",
    "        start = section['start']*1000\n",
    "        if (start > len(audio)): break # If the piano part ends earlier\n",
    "\n",
    "        end = section['start']*1000 + section['duration']*1000\n",
    "        if (end > len(audio)): end = len(audio)\n",
    "        cut_audio = audio[start:end]\n",
    "        \n",
    "        # Remove start and end silence\n",
    "        cut_audio = strip_silence(cut_audio)\n",
    "        if len(cut_audio) < 4000: continue # If it's shorter than 4s don't save it\n",
    "\n",
    "        cut_audio.export('./tmp/render_cut.wav', format='wav')\n",
    "\n",
    "        data = {\n",
    "            'song': song[:-4],\n",
    "            'artist': artist,\n",
    "            'instrument': instrument[:-4],\n",
    "            'genre': specific_genre,\n",
    "            'tempo': int(section['tempo']),\n",
    "            'key': key_dict[section['key']],\n",
    "            'mode': mode_dict[section['mode']],\n",
    "            'energy': energy,\n",
    "            'danceability': danceability,\n",
    "            'pedals': []\n",
    "        }\n",
    "\n",
    "        # Add filters\n",
    "        board = Pedalboard([Compressor()])\n",
    "        num_pedals = random.choices([0, 1, 2, 3], weights=[40, 40, 15, 5], k=1)[0]\n",
    "        pedals = random.sample([0, 1, 2, 3, 4], num_pedals)\n",
    "        for pedal in pedals:\n",
    "            match pedal:\n",
    "                case 0:\n",
    "                    rate_hz = random.uniform(0.1, 10.0)\n",
    "                    depth = random.uniform(0.0, 1.0)\n",
    "                    centre_frequency_hz = random.uniform(100.0, 10000.0)\n",
    "                    feedback = 0.0\n",
    "                    mix = 0.5\n",
    "                    board.append(Phaser(rate_hz=rate_hz, depth=depth, centre_frequency_hz=centre_frequency_hz, feedback=feedback, mix=mix))\n",
    "                    data['pedals'].append({\n",
    "                        \"name\": \"Phaser\",\n",
    "                        \"rate_hz\": rate_hz,\n",
    "                        \"depth\": depth,\n",
    "                        \"centre_frequency_hz\": centre_frequency_hz,\n",
    "                    })\n",
    "                case 1:\n",
    "                    rate_hz = random.uniform(0.1, 10.0)\n",
    "                    depth = random.uniform(0.0, 1.0)\n",
    "                    centre_delay_ms = random.uniform(1.0, 50.0)\n",
    "                    feedback = 0.0\n",
    "                    mix = 0.5\n",
    "                    board.append(Chorus(rate_hz=rate_hz, depth=depth, centre_delay_ms=centre_delay_ms, feedback=feedback, mix=mix))\n",
    "                    data['pedals'].append({\n",
    "                        \"name\": \"Chorus\",\n",
    "                        \"rate_hz\": rate_hz,\n",
    "                        \"depth\": depth,\n",
    "                        \"centre_delay_ms\": centre_delay_ms,\n",
    "                    })\n",
    "                case 2:\n",
    "                    bit_depth = 8 + 8*random.randint(0, 1) # 8 or 16\n",
    "                    board.append(Bitcrush(bit_depth=bit_depth))\n",
    "                    data['pedals'].append({\n",
    "                        'name': 'Bitcrush',\n",
    "                        'bit_depth': bit_depth\n",
    "                    })\n",
    "                case 3:\n",
    "                    delay_seconds = random.uniform(0.01, 5.0)\n",
    "                    feedback = 0.0\n",
    "                    mix = 0.5\n",
    "                    board.append(Delay(delay_seconds=delay_seconds, feedback=feedback, mix=mix))\n",
    "                    data['pedals'].append({\n",
    "                        \"name\": \"Delay\",\n",
    "                        \"delay_seconds\": delay_seconds\n",
    "                    })\n",
    "                case 4:\n",
    "                    room_size = random.uniform(0.0, 1.0)\n",
    "                    damping = random.uniform(0.0, 1.0)\n",
    "                    wet_level = random.uniform(0.0, 1.0)\n",
    "                    dry_level = random.uniform(0.0, 1.0)\n",
    "                    width = random.uniform(0.0, 1.0)\n",
    "                    freeze_mode = random.uniform(0.0, 1.0)\n",
    "                    board.append(Reverb(room_size=room_size, damping=damping, wet_level=wet_level, dry_level=dry_level, width=width, freeze_mode=freeze_mode))\n",
    "                    data['pedals'].append({\n",
    "                        \"name\": \"Reverb\",\n",
    "                        \"room_size\": room_size,\n",
    "                        \"damping\": damping,\n",
    "                        \"wet_level\": wet_level,\n",
    "                        \"dry_level\": dry_level,\n",
    "                        \"width\": width,\n",
    "                        \"freeze_mode\": freeze_mode\n",
    "                    })\n",
    "\n",
    "\n",
    "        with AudioFile('./tmp/render_cut.wav') as f:\n",
    "            with AudioFile(f'./renders/{id:07}.wav', 'w', f.samplerate, f.num_channels) as o:\n",
    "                while f.tell() < f.frames:\n",
    "                    chunk = f.read(f.samplerate)\n",
    "                    effected = board(chunk, f.samplerate, reset=False)\n",
    "                    o.write(effected)\n",
    "\n",
    "        # Save metadata\n",
    "        with open(f'./renders/{id:07}.json', 'w') as json_file:\n",
    "            json.dump(data, json_file)\n",
    "        \n",
    "        id += 1\n",
    "\n",
    "os.remove(f'./tmp/render_cut.wav')\n",
    "os.remove(f'./tmp/render.wav')\n",
    "os.rmdir('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import pyloudnorm as pyln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize renders loudness\n",
    "for file in os.listdir('renders'):\n",
    "    if file.endswith('.wav'):\n",
    "        data, rate = sf.read(f'renders/{file}')\n",
    "        meter = pyln.Meter(rate) # create BS.1770 meter\n",
    "        loudness = meter.integrated_loudness(data)\n",
    "        loudness_normalized_audio = pyln.normalize.loudness(data, loudness, -12.0)\n",
    "        sf.write(f'renders/{file}', loudness_normalized_audio, rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
